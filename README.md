# Neural Transducer

This repo contains a set of neural transducer, e.g. sequence-to-sequence model, focusing on character-level tasks. It powers the following papars and workshop.

- Ekaterina Vylomova, Jennifer White, Elizabeth Salesky, Sabrina J. Mielke, Shijie Wu, Edoardo Ponti, Rowan Hall Maudslay, Ran Zmigrod, Josef Valvoda, Svetlana Toldova, Francis Tyers, Elena Klyachko, Ilya Yegorov, Natalia Krizhanovsky, Paula Czarnowska, Irene Nikkarinen, Andrew Krizhanovsky, Tiago Pimentel, Lucas Torroba Hennigen, Christo Kirov, Garrett Nicolai, Adina Williams, Antonios Anastasopoulos, Hilaria Cruz, Eleanor Chodroff, Ryan Cotterell, Miikka Silfverberg, and Mans Hulden. [*SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological Inflection*](https://arxiv.org/abs/2006.11572). SIGMORPHON. 2020. ([Experiments Detail](example/sigmorphon2020-shared-tasks))
- Arya D McCarthy, Ekaterina Vylomova, Shijie Wu, Chaitanya Malaviya, Lawrence Wolf-Sonkin, Garrett Nicolai, Miikka Silfverberg, Sebastian J Mielke, Jeffrey Heinz, Ryan Cotterell, and Mans Hulden. [*The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection*](https://www.aclweb.org/anthology/W19-4226/). SIGMORPHON. 2019. ([Experiments Detail](example/sigmorphon2019-shared-tasks))
- Shijie Wu, Ryan Cotterell, and Timothy J O'Donnell. [*Morphological Irregularity Correlates with Frequency*](https://arxiv.org/abs/1906.11483). ACL. 2019. ([Experiments Detail](example/irregularity-vs-frequency))
- Shijie Wu, and Ryan Cotterell. [*Exact Hard Monotonic Attention for Character-Level Transduction*](https://arxiv.org/abs/1905.06319). ACL. 2019. ([Experiments Detail](example/hard-monotonic-attention))
- Chaitanya Malaviya*, Shijie Wu*, and Ryan Cotterell. [*A Simple Joint Model for Improved Contextual Neural Lemmatization*](https://arxiv.org/abs/1904.02306). NAACL. 2019. ([Experiments Detail](example/contextual-lemmatization))
- Shijie Wu, Pamela Shapiro, and Ryan Cotterell. [*Hard Non-Monotonic Attention for Character-Level Transduction*](https://arxiv.org/abs/1808.10024). EMNLP. 2018. ([Experiments Detail](example/hard-attention))


## Dependencies

- python 3
- pytorch==1.4
- numpy
- tqdm
- fire


## Install

```bash
make
```


## License

MIT
